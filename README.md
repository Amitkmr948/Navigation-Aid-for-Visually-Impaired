# ğŸ§­ Navigation Aid for Visually Impaired

A smart, wearable, and offline-capable navigation device built for visually impaired individuals. It uses real-time object detection, LiDAR-based depth sensing, and haptic/audio feedback to assist users in navigating indoor and outdoor environments independently and safely.

---

## ğŸ“Œ Project Overview

This project provides a hands-free mobility solution for the visually impaired by integrating AI vision, depth sensing, and multi-modal feedback in a lightweight wearable format. Designed with affordability and usability in mind, it offers real-time obstacle detection without relying on internet or GPS.

---

## ğŸŒŸ Key Features

- âœ… **LiDAR and Ultrasonic Sensors** for real-time distance sensing
- âœ… **YOLOv8 Object Detection** (30+ classes)
- âœ… **Vibration Feedback** for obstacle proximity
- âœ… **Audio Guidance** using offline text-to-speech and Bluetooth
- âœ… **Offline Operation** (no internet or GPS required)
- âœ… **Low-Cost & Modular** (â‚¹19,961 total fabrication cost)

---

## ğŸ—ï¸ System Architecture

### ğŸ”Œ Hardware Flow


# [Camera] â†’ [Raspberry Pi 5 + YOLOv8] â†’ Object Detection
# â†“
# [ESP32 Microcontroller + Sensors (LiDAR, Ultrasonic)]
# â†“
# [Vibration Motors] + [Bluetooth Audio Output]
